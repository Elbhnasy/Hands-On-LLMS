{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914f999f",
   "metadata": {},
   "source": [
    "## Ollama \n",
    "* genration and chat completion\n",
    "    * [Ollama  completion refrence](https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ccc4f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2:latest',\n",
       " 'created_at': '2025-05-02T15:11:08.327216473Z',\n",
       " 'response': 'Here is a summary of the tone, intent, and structure of the given text:\\n\\n• **Tone:** The tone of this sentence is informal, friendly, and welcoming. It sets a casual and approachable tone.\\n• **Intent:** The intent of this sentence is to initiate a conversation or establish a connection with the person being addressed. It\\'s a greeting that invites the other person to respond.\\n• **Structure:** The structure of this sentence is simple and straightforward. It consists of a single sentence with a short question (\"how are you?\") followed by a polite expression of inquiry.',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'context': [128006,\n",
       "  9125,\n",
       "  128007,\n",
       "  271,\n",
       "  38766,\n",
       "  1303,\n",
       "  33025,\n",
       "  2696,\n",
       "  25,\n",
       "  6790,\n",
       "  220,\n",
       "  2366,\n",
       "  18,\n",
       "  271,\n",
       "  128009,\n",
       "  128006,\n",
       "  882,\n",
       "  128007,\n",
       "  271,\n",
       "  9370,\n",
       "  5730,\n",
       "  553,\n",
       "  279,\n",
       "  16630,\n",
       "  11,\n",
       "  7537,\n",
       "  11,\n",
       "  323,\n",
       "  6070,\n",
       "  315,\n",
       "  279,\n",
       "  2768,\n",
       "  1495,\n",
       "  304,\n",
       "  220,\n",
       "  18,\n",
       "  17889,\n",
       "  3585,\n",
       "  25,\n",
       "  22691,\n",
       "  11,\n",
       "  1268,\n",
       "  527,\n",
       "  499,\n",
       "  30,\n",
       "  128009,\n",
       "  128006,\n",
       "  78191,\n",
       "  128007,\n",
       "  271,\n",
       "  8586,\n",
       "  374,\n",
       "  264,\n",
       "  12399,\n",
       "  315,\n",
       "  279,\n",
       "  16630,\n",
       "  11,\n",
       "  7537,\n",
       "  11,\n",
       "  323,\n",
       "  6070,\n",
       "  315,\n",
       "  279,\n",
       "  2728,\n",
       "  1495,\n",
       "  1473,\n",
       "  6806,\n",
       "  3146,\n",
       "  51,\n",
       "  606,\n",
       "  68063,\n",
       "  578,\n",
       "  16630,\n",
       "  315,\n",
       "  420,\n",
       "  11914,\n",
       "  374,\n",
       "  42887,\n",
       "  11,\n",
       "  11919,\n",
       "  11,\n",
       "  323,\n",
       "  36387,\n",
       "  13,\n",
       "  1102,\n",
       "  7437,\n",
       "  264,\n",
       "  16736,\n",
       "  323,\n",
       "  5603,\n",
       "  481,\n",
       "  16630,\n",
       "  627,\n",
       "  6806,\n",
       "  3146,\n",
       "  11797,\n",
       "  68063,\n",
       "  578,\n",
       "  7537,\n",
       "  315,\n",
       "  420,\n",
       "  11914,\n",
       "  374,\n",
       "  311,\n",
       "  39201,\n",
       "  264,\n",
       "  10652,\n",
       "  477,\n",
       "  5813,\n",
       "  264,\n",
       "  3717,\n",
       "  449,\n",
       "  279,\n",
       "  1732,\n",
       "  1694,\n",
       "  20669,\n",
       "  13,\n",
       "  1102,\n",
       "  596,\n",
       "  264,\n",
       "  43213,\n",
       "  430,\n",
       "  45510,\n",
       "  279,\n",
       "  1023,\n",
       "  1732,\n",
       "  311,\n",
       "  6013,\n",
       "  627,\n",
       "  6806,\n",
       "  3146,\n",
       "  23807,\n",
       "  68063,\n",
       "  578,\n",
       "  6070,\n",
       "  315,\n",
       "  420,\n",
       "  11914,\n",
       "  374,\n",
       "  4382,\n",
       "  323,\n",
       "  31439,\n",
       "  13,\n",
       "  1102,\n",
       "  17610,\n",
       "  315,\n",
       "  264,\n",
       "  3254,\n",
       "  11914,\n",
       "  449,\n",
       "  264,\n",
       "  2875,\n",
       "  3488,\n",
       "  3573,\n",
       "  5269,\n",
       "  527,\n",
       "  499,\n",
       "  30,\n",
       "  909,\n",
       "  8272,\n",
       "  555,\n",
       "  264,\n",
       "  48887,\n",
       "  7645,\n",
       "  315,\n",
       "  26981,\n",
       "  13],\n",
       " 'total_duration': 9291045512,\n",
       " 'load_duration': 2145891878,\n",
       " 'prompt_eval_count': 51,\n",
       " 'prompt_eval_duration': 223536567,\n",
       " 'eval_count': 119,\n",
       " 'eval_duration': 6920461450}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the API URL for the Ollama generation endpoint\n",
    "generation_api_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Specify the model to be used for text generation\n",
    "model = \"llama3.2:latest\"\n",
    "\n",
    "# Define the input text to be summarized\n",
    "text = \"Hello, how are you?\"\n",
    "\n",
    "# Send a POST request to the Ollama API with the required parameters\n",
    "response = requests.post(\n",
    "    generation_api_url,\n",
    "    json={\n",
    "        \"model\": model,  # Specify the model to use\n",
    "        \"prompt\": f\"Summarize the tone, intent, and structure of the following text in 3 bullet points: {text}\",  # Define the task prompt\n",
    "        \"stream\": False,  \n",
    "        \"options\": {  \n",
    "            \"temperature\": 0.7,  \n",
    "            \"top_p\": 0.9,  \n",
    "            \"top_k\": 50,  \n",
    "            \"repetition_penalty\": 1.2  # Penalize repetition in the output\n",
    "        }\n",
    "    }\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fa156b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a summary of the tone, intent, and structure of the given text:\\n\\n• **Tone:** The tone of this sentence is informal, friendly, and welcoming. It sets a casual and approachable tone.\\n• **Intent:** The intent of this sentence is to initiate a conversation or establish a connection with the person being addressed. It\\'s a greeting that invites the other person to respond.\\n• **Structure:** The structure of this sentence is simple and straightforward. It consists of a single sentence with a short question (\"how are you?\") followed by a polite expression of inquiry.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae0ceba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Here is a summary of the tone, intent, and structure of the given text:\\n'\n",
      " '\\n'\n",
      " '• **Tone:** The tone of this sentence is informal, friendly, and welcoming. '\n",
      " 'It sets a casual and approachable tone.\\n'\n",
      " '• **Intent:** The intent of this sentence is to initiate a conversation or '\n",
      " \"establish a connection with the person being addressed. It's a greeting that \"\n",
      " 'invites the other person to respond.\\n'\n",
      " '• **Structure:** The structure of this sentence is simple and '\n",
      " 'straightforward. It consists of a single sentence with a short question '\n",
      " '(\"how are you?\") followed by a polite expression of inquiry.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pprint\n",
    "pprint(response.json()['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0e7a3",
   "metadata": {},
   "source": [
    "##### chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14ca5f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2:latest',\n",
       " 'created_at': '2025-05-02T15:29:00.117193313Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'Egypt is a country rich in history, culture, and natural beauty. Here are some of the most beautiful things in Egypt:\\n\\n1. **Pyramids of Giza**: No list of Egyptian wonders would be complete without these iconic pyramids, one of the Seven Wonders of the Ancient World.\\n2. **Nile River**: The lifeblood of ancient Egypt, the Nile is a stunning river that winds its way through the heart of the country, offering breathtaking views and opportunities for boat rides and fel'},\n",
       " 'done_reason': 'length',\n",
       " 'done': True,\n",
       " 'total_duration': 5736191793,\n",
       " 'load_duration': 23456757,\n",
       " 'prompt_eval_count': 36,\n",
       " 'prompt_eval_duration': 14679662,\n",
       " 'eval_count': 100,\n",
       " 'eval_duration': 5697555450}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Define the API URL for the Ollama chat endpoint\n",
    "chat_api_url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "# Specify the model to be used for chat\n",
    "model = \"llama3.2:latest\"\n",
    "\n",
    "# Define the input text for the chat\n",
    "text = \"Hello! what are the beautiful things in egypt?\"\n",
    "\n",
    "# Send a POST request to the Ollama API with the required parameters    \n",
    "response = requests.post(\n",
    "    chat_api_url,\n",
    "    json={\n",
    "        \"model\": model,  \n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\": text}  \n",
    "        ],\n",
    "        \"stream\": False,  \n",
    "        \"options\": {  \n",
    "            \"temperature\": 0.7,  \n",
    "            \"top_p\": 0.9,  \n",
    "            \"top_k\": 50,\n",
    "            \"seed\" : 101,  \n",
    "            \"repetition_penalty\": 1.2,\n",
    "            \"num_predict\": 100,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73678e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Egypt is a country rich in history, culture, and natural beauty. Here are '\n",
      " 'some of the most beautiful things in Egypt:\\n'\n",
      " '\\n'\n",
      " '1. **Pyramids of Giza**: No list of Egyptian wonders would be complete '\n",
      " 'without these iconic pyramids, one of the Seven Wonders of the Ancient '\n",
      " 'World.\\n'\n",
      " '2. **Nile River**: The lifeblood of ancient Egypt, the Nile is a stunning '\n",
      " 'river that winds its way through the heart of the country, offering '\n",
      " 'breathtaking views and opportunities for boat rides and fel')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pprint\n",
    "\n",
    "pprint(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d934b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_settings\n",
    "from openai import OpenAI\n",
    "import os \n",
    "\n",
    "setting = get_settings()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = setting.OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "llm_model = setting.LLM_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caabebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "from langchain_huggingface import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and tokenizer setup\n",
    "model_id = env_values['MODEL_ID']\n",
    "\n",
    "# Configure 8-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                                quantization_config=quantization_config,\n",
    "                                                device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=base_model,\n",
    "                tokenizer=tokenizer,\n",
    "                max_length=256,\n",
    "                truncation=True,  # Explicitly enable truncation\n",
    "                do_sample=True,\n",
    "                temperature=0.6,\n",
    "                top_p=0.95,\n",
    "                repetition_penalty=1.2)\n",
    "\n",
    "# Initialize LangChain HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c57802",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Suggest 2 ways to lose my weight.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "print(llm.invoke(template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940cc1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "Suggest 2 ways to lose my weight.\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_2 = \"\"\"\n",
    "Tell me a joke\n",
    "\"\"\".strip()\n",
    "\n",
    "llm_results = llm.generate([ prompt_1, prompt_2 ])\n",
    "llm_results.generations[1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct pipeline usage\n",
    "pipeline_output = pipe(template, return_full_text=False)\n",
    "print(\"Pipeline Output:\", pipeline_output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6b00b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
