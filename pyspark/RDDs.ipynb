{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5572a2",
   "metadata": {},
   "source": [
    "# PySpark RDDs (Resilient Distributed Datasets) - Complete Guide\n",
    "\n",
    "This notebook covers everything you need to know about PySpark RDDs for quick revision.\n",
    "\n",
    "## ðŸ“š Table of Contents\n",
    "\n",
    "1. [Setup & Initialization](#setup)\n",
    "2. [RDD Basics](#basics)\n",
    "   - Creating RDDs\n",
    "   - Understanding Partitions\n",
    "3. [Transformations](#transformations)\n",
    "   - Narrow Transformations (map, filter, flatMap)\n",
    "   - Wide Transformations (groupBy, join, reduceByKey)\n",
    "4. [Actions](#actions)\n",
    "   - collect(), take(), count()\n",
    "   - reduce(), aggregate functions\n",
    "5. [Working with Text Files](#text-files)\n",
    "6. [Caching & Persistence](#caching)\n",
    "7. [Key Concepts](#concepts)\n",
    "   - Lazy Evaluation\n",
    "   - Lineage\n",
    "   - Narrow vs Wide Transformations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafc3ee",
   "metadata": {},
   "source": [
    "## 1. Setup & Initialization {#setup}\n",
    "\n",
    "Initialize SparkSession and SparkContext for working with RDDs.\n",
    "\n",
    "**Key Points:**\n",
    "- SparkSession is the entry point for Spark SQL\n",
    "- SparkContext (sc) is needed specifically for RDD operations\n",
    "- Setting log level to ERROR reduces console noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54aacd",
   "metadata": {},
   "source": [
    "## 2. RDD Basics {#basics}\n",
    "\n",
    "### What is an RDD?\n",
    "- **Resilient**: Fault-tolerant through lineage tracking\n",
    "- **Distributed**: Data spread across cluster nodes\n",
    "- **Dataset**: Collection of elements\n",
    "\n",
    "### Creating RDDs\n",
    "RDDs can be created from:\n",
    "1. Parallelizing existing collections\n",
    "2. Reading from external storage (files, databases)\n",
    "3. Transforming existing RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31f77f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark.stop()\n",
    "spark= SparkSession.builder.appName(\"Basics\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64695f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:297"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.arange(1, 100)\n",
    "\n",
    "# Create RDD\n",
    "rdd0 = sc.parallelize(data)\n",
    "rdd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b837cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:56"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square the elements\n",
    "rdd1 = rdd0.map(lambda x: x**2)\n",
    "rdd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4508edf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:56"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 20 to each element\n",
    "rdd2 = rdd1.map(lambda x: x + 20)\n",
    "rdd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd216ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ce115",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Transformations {#transformations}\n",
    "\n",
    "### ðŸ“Œ Key Concept: Lazy Evaluation\n",
    "Transformations are **lazy** - they don't execute immediately. Spark builds a **lineage graph** and only computes results when an **action** is called.\n",
    "\n",
    "### Types of Transformations:\n",
    "1. **Narrow Transformations**: Each input partition contributes to at most one output partition (no shuffle)\n",
    "2. **Wide Transformations**: Input partitions contribute to multiple output partitions (requires shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "533c7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd1.map(lambda x: x - 5)\n",
    "rdd5 = rdd2.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed9d36",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Demonstration: Multiple Transformations\n",
    "Creating multiple transformation branches from the same RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c07f5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:56"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1462f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Caching & Persistence {#caching}\n",
    "\n",
    "### Why Cache?\n",
    "When an RDD is used multiple times, caching stores it in memory to avoid recomputation.\n",
    "\n",
    "**Use cases:**\n",
    "- Multiple actions on same RDD\n",
    "- Iterative algorithms\n",
    "- Interactive analysis\n",
    "\n",
    "**Methods:**\n",
    "- `cache()`: Store in memory (MEMORY_ONLY)\n",
    "- `persist()`: More storage level options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdc9cc",
   "metadata": {},
   "source": [
    "### Cache rdd1 to avoid recomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84e8db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.int64(-4),\n",
       " np.int64(-1),\n",
       " np.int64(4),\n",
       " np.int64(11),\n",
       " np.int64(20),\n",
       " np.int64(31),\n",
       " np.int64(44),\n",
       " np.int64(59),\n",
       " np.int64(76),\n",
       " np.int64(95),\n",
       " np.int64(116),\n",
       " np.int64(139),\n",
       " np.int64(164),\n",
       " np.int64(191),\n",
       " np.int64(220),\n",
       " np.int64(251),\n",
       " np.int64(284),\n",
       " np.int64(319),\n",
       " np.int64(356),\n",
       " np.int64(395),\n",
       " np.int64(436),\n",
       " np.int64(479),\n",
       " np.int64(524),\n",
       " np.int64(571),\n",
       " np.int64(620),\n",
       " np.int64(671),\n",
       " np.int64(724),\n",
       " np.int64(779),\n",
       " np.int64(836),\n",
       " np.int64(895),\n",
       " np.int64(956),\n",
       " np.int64(1019),\n",
       " np.int64(1084),\n",
       " np.int64(1151),\n",
       " np.int64(1220),\n",
       " np.int64(1291),\n",
       " np.int64(1364),\n",
       " np.int64(1439),\n",
       " np.int64(1516),\n",
       " np.int64(1595),\n",
       " np.int64(1676),\n",
       " np.int64(1759),\n",
       " np.int64(1844),\n",
       " np.int64(1931),\n",
       " np.int64(2020),\n",
       " np.int64(2111),\n",
       " np.int64(2204),\n",
       " np.int64(2299),\n",
       " np.int64(2396),\n",
       " np.int64(2495),\n",
       " np.int64(2596),\n",
       " np.int64(2699),\n",
       " np.int64(2804),\n",
       " np.int64(2911),\n",
       " np.int64(3020),\n",
       " np.int64(3131),\n",
       " np.int64(3244),\n",
       " np.int64(3359),\n",
       " np.int64(3476),\n",
       " np.int64(3595),\n",
       " np.int64(3716),\n",
       " np.int64(3839),\n",
       " np.int64(3964),\n",
       " np.int64(4091),\n",
       " np.int64(4220),\n",
       " np.int64(4351),\n",
       " np.int64(4484),\n",
       " np.int64(4619),\n",
       " np.int64(4756),\n",
       " np.int64(4895),\n",
       " np.int64(5036),\n",
       " np.int64(5179),\n",
       " np.int64(5324),\n",
       " np.int64(5471),\n",
       " np.int64(5620),\n",
       " np.int64(5771),\n",
       " np.int64(5924),\n",
       " np.int64(6079),\n",
       " np.int64(6236),\n",
       " np.int64(6395),\n",
       " np.int64(6556),\n",
       " np.int64(6719),\n",
       " np.int64(6884),\n",
       " np.int64(7051),\n",
       " np.int64(7220),\n",
       " np.int64(7391),\n",
       " np.int64(7564),\n",
       " np.int64(7739),\n",
       " np.int64(7916),\n",
       " np.int64(8095),\n",
       " np.int64(8276),\n",
       " np.int64(8459),\n",
       " np.int64(8644),\n",
       " np.int64(8831),\n",
       " np.int64(9020),\n",
       " np.int64(9211),\n",
       " np.int64(9404),\n",
       " np.int64(9599),\n",
       " np.int64(9796)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff74de6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Actions {#actions}\n",
    "\n",
    "### What are Actions?\n",
    "Actions **trigger execution** of transformations and return results to the driver or write to storage.\n",
    "\n",
    "### Common Actions:\n",
    "- `collect()`: Return all elements to driver (âš ï¸ careful with large datasets!)\n",
    "- `take(n)`: Return first n elements\n",
    "- `count()`: Count number of elements\n",
    "- `reduce()`: Aggregate elements using a function\n",
    "- `first()`, `max()`, `min()`, `mean()`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3d0b6",
   "metadata": {},
   "source": [
    "### Examples of Actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2138078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(42),\n",
       " np.int64(48),\n",
       " np.int64(58),\n",
       " np.int64(72),\n",
       " np.int64(90),\n",
       " np.int64(112),\n",
       " np.int64(138),\n",
       " np.int64(168),\n",
       " np.int64(202),\n",
       " np.int64(240),\n",
       " np.int64(282),\n",
       " np.int64(328),\n",
       " np.int64(378),\n",
       " np.int64(432),\n",
       " np.int64(490),\n",
       " np.int64(552),\n",
       " np.int64(618),\n",
       " np.int64(688),\n",
       " np.int64(762),\n",
       " np.int64(840),\n",
       " np.int64(922),\n",
       " np.int64(1008),\n",
       " np.int64(1098),\n",
       " np.int64(1192),\n",
       " np.int64(1290),\n",
       " np.int64(1392),\n",
       " np.int64(1498),\n",
       " np.int64(1608),\n",
       " np.int64(1722),\n",
       " np.int64(1840),\n",
       " np.int64(1962),\n",
       " np.int64(2088),\n",
       " np.int64(2218),\n",
       " np.int64(2352),\n",
       " np.int64(2490),\n",
       " np.int64(2632),\n",
       " np.int64(2778),\n",
       " np.int64(2928),\n",
       " np.int64(3082),\n",
       " np.int64(3240),\n",
       " np.int64(3402),\n",
       " np.int64(3568),\n",
       " np.int64(3738),\n",
       " np.int64(3912),\n",
       " np.int64(4090),\n",
       " np.int64(4272),\n",
       " np.int64(4458),\n",
       " np.int64(4648),\n",
       " np.int64(4842),\n",
       " np.int64(5040),\n",
       " np.int64(5242),\n",
       " np.int64(5448),\n",
       " np.int64(5658),\n",
       " np.int64(5872),\n",
       " np.int64(6090),\n",
       " np.int64(6312),\n",
       " np.int64(6538),\n",
       " np.int64(6768),\n",
       " np.int64(7002),\n",
       " np.int64(7240),\n",
       " np.int64(7482),\n",
       " np.int64(7728),\n",
       " np.int64(7978),\n",
       " np.int64(8232),\n",
       " np.int64(8490),\n",
       " np.int64(8752),\n",
       " np.int64(9018),\n",
       " np.int64(9288),\n",
       " np.int64(9562),\n",
       " np.int64(9840),\n",
       " np.int64(10122),\n",
       " np.int64(10408),\n",
       " np.int64(10698),\n",
       " np.int64(10992),\n",
       " np.int64(11290),\n",
       " np.int64(11592),\n",
       " np.int64(11898),\n",
       " np.int64(12208),\n",
       " np.int64(12522),\n",
       " np.int64(12840),\n",
       " np.int64(13162),\n",
       " np.int64(13488),\n",
       " np.int64(13818),\n",
       " np.int64(14152),\n",
       " np.int64(14490),\n",
       " np.int64(14832),\n",
       " np.int64(15178),\n",
       " np.int64(15528),\n",
       " np.int64(15882),\n",
       " np.int64(16240),\n",
       " np.int64(16602),\n",
       " np.int64(16968),\n",
       " np.int64(17338),\n",
       " np.int64(17712),\n",
       " np.int64(18090),\n",
       " np.int64(18472),\n",
       " np.int64(18858),\n",
       " np.int64(19248),\n",
       " np.int64(19642)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a3037ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(-4),\n",
       " np.int64(-1),\n",
       " np.int64(4),\n",
       " np.int64(11),\n",
       " np.int64(20),\n",
       " np.int64(31),\n",
       " np.int64(44),\n",
       " np.int64(59),\n",
       " np.int64(76),\n",
       " np.int64(95)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5529146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7277e3d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Working with Text Files {#text-files}\n",
    "\n",
    "RDDs can easily work with text files. Each line becomes an element in the RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2d73b",
   "metadata": {},
   "source": [
    "### Create a sample text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0801a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "Hello, this is an example text file.\n",
    "It contains multiple lines of text.\n",
    "This is the third line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93768b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example.txt MapPartitionsRDD[9] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddfile = sc.textFile(\"example.txt\")\n",
    "rddfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e20f0c",
   "metadata": {},
   "source": [
    "### Load text file into RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e74afe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, this is an example text file.',\n",
       " 'It contains multiple lines of text.',\n",
       " 'This is the third line.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddfile.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "959e14f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, this is an example text file.', 'It contains multiple lines of text.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddfile.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73177dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the third line.']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddthird = rddfile.filter(lambda x: \"third\" in x)\n",
    "rddthird.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169bd00",
   "metadata": {},
   "source": [
    "### Filter lines containing specific text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3e19dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 35, 23]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddfile2 = rddfile.map(lambda x: len(x))\n",
    "rddfile2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bd992",
   "metadata": {},
   "source": [
    "### Get length of each line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0da4cba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(1), np.int64(4), np.int64(9), np.int64(16), np.int64(25)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map --> narrow transformation\n",
    "\n",
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "rddsq = rdd0.map(square)\n",
    "rddsq.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef7a3a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Narrow Transformations {#narrow}\n",
    "\n",
    "**Narrow transformations** don't require data shuffling across partitions. Each input partition contributes to exactly one output partition.\n",
    "\n",
    "### Examples: map, filter, flatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c2284",
   "metadata": {},
   "source": [
    "### map() with custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ce53229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, this is an example text file.',\n",
       " 'It contains multiple lines of text.',\n",
       " 'This is the third line.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtrdd = sc.textFile(\"example.txt\")\n",
    "txtrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "746690ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello,', 'this', 'is', 'an', 'example', 'text', 'file.'],\n",
       " ['It', 'contains', 'multiple', 'lines', 'of', 'text.'],\n",
       " ['This', 'is', 'the', 'third', 'line.']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def splitter(text):\n",
    "    return text.split()\n",
    "\n",
    "txtrdd2 = txtrdd.map(splitter)\n",
    "txtrdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d0a8c",
   "metadata": {},
   "source": [
    "### map() vs flatMap()\n",
    "\n",
    "**map()**: Returns one output element per input element (can be a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fbe0243d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'text',\n",
       " 'file.',\n",
       " 'It',\n",
       " 'contains',\n",
       " 'multiple',\n",
       " 'lines',\n",
       " 'of',\n",
       " 'text.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line.']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtrdd3 = txtrdd.flatMap(splitter)\n",
    "txtrdd3.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d632400",
   "metadata": {},
   "source": [
    "**flatMap()**: Flattens the output - returns multiple elements per input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b0929",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Wide Transformations {#wide}\n",
    "\n",
    "**Wide transformations** require shuffling data across partitions. More expensive but necessary for certain operations.\n",
    "\n",
    "### Examples: groupBy, groupByKey, join, reduceByKey\n",
    "\n",
    "**âš ï¸ Performance Tip:** Prefer `reduceByKey()` over `groupByKey()` when possible - it reduces data before shuffling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675593b9",
   "metadata": {},
   "source": [
    "### groupBy() Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e6cfdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[18] at readRDDFromFile at PythonRDD.scala:297"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstName = [\"Alice\", \"Belal\",\"Hany\",\"Bob\", \"Charlie\", \"David\", \"Eyad\",\"Eve\", \"Frank\",\"Farida\", \"Grace\", \"Heidi\"]\n",
    "lstN = sc.parallelize(lstName, 3)\n",
    "lstN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c7fea9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_grouped = lstN.groupBy(lambda x:x[0])\n",
    "names_g = rdd_grouped.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05bdb4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hany', 'Heidi']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(names_g[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4958ab6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('H', ['Hany', 'Heidi']),\n",
       " ('E', ['Eyad', 'Eve']),\n",
       " ('A', ['Alice']),\n",
       " ('C', ['Charlie']),\n",
       " ('D', ['David']),\n",
       " ('B', ['Belal', 'Bob']),\n",
       " ('F', ['Frank', 'Farida']),\n",
       " ('G', ['Grace'])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newlist =  [(k,list(v)) for (k, v) in names_g]\n",
    "newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a3173627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', [2, 4]), ('C', [5]), ('A', [1, 3])]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pairs = sc.parallelize([('A', 1), ('B', 2), ('A', 3), ('B', 4), ('C', 5)])\n",
    "\n",
    "grouped = pairs.groupByKey()\n",
    "\n",
    "# Convert grouped values to lists for display\n",
    "result = [(k, list(v)) for k, v in grouped.collect()]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444a11a",
   "metadata": {},
   "source": [
    "### groupByKey() Example:\n",
    "Groups values by key in key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6a61aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('b', (2, 'banana')), ('a', (1, 'apple'))]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_a = sc.parallelize([('a', 1), ('b', 2), ('c', 3)])\n",
    "rdd_b = sc.parallelize([('a', 'apple'), ('b', 'banana'), ('d', 'date')])\n",
    "\n",
    "joined_rdd = rdd_a.join(rdd_b)\n",
    "joined_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2292d25",
   "metadata": {},
   "source": [
    "### join() Example:\n",
    "Performs inner join on two key-value RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42a3b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4950)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "total_sum = rdd0.reduce(add)\n",
    "total_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af4872",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Aggregate Actions {#aggregate}\n",
    "\n",
    "### reduce() - Aggregate all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e14f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3316.6666666666665\n",
      "Max: 9801\n",
      "Standard Deviation: 2949.5862233352136\n",
      "Variance: 8700058.888888888\n",
      "Min: 1\n"
     ]
    }
   ],
   "source": [
    "mean_val = rdd1.mean()\n",
    "max_val = rdd1.max()\n",
    "stddev_val = rdd1.stdev()\n",
    "variance_val = rdd1.variance()\n",
    "min_val = rdd1.min()\n",
    "\n",
    "print(f\"Mean: {mean_val}\")\n",
    "print(f\"Max: {max_val}\")\n",
    "print(f\"Standard Deviation: {stddev_val}\")\n",
    "print(f\"Variance: {variance_val}\")\n",
    "print(f\"Min: {min_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc7635",
   "metadata": {},
   "source": [
    "### Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b048599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', 6), ('C', 5), ('A', 4)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = sc.parallelize([('A', 1), ('B', 2), ('A', 3), ('B', 4), ('C', 5)])\n",
    "\n",
    "reduced = pairs.reduceByKey(lambda a, b: a + b)\n",
    "reduced.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6247b",
   "metadata": {},
   "source": [
    "### reduceByKey() - More efficient than groupByKey()\n",
    "\n",
    "Reduces values for each key **before** shuffling, minimizing data transfer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc7b406",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ“ Key Concepts Summary {#concepts}\n",
    "\n",
    "### 1. **Lazy Evaluation**\n",
    "- Transformations are recorded but not executed immediately\n",
    "- Spark builds a **DAG (Directed Acyclic Graph)** of operations\n",
    "- Actual computation happens only when an **action** is called\n",
    "- Benefits: Optimization opportunities, avoiding unnecessary computation\n",
    "\n",
    "### 2. **Lineage**\n",
    "- Spark tracks the sequence of transformations (lineage graph)\n",
    "- Used for fault tolerance - can recompute lost partitions\n",
    "- No need for replication of data\n",
    "\n",
    "### 3. **Transformations vs Actions**\n",
    "\n",
    "| Transformations | Actions |\n",
    "|----------------|---------|\n",
    "| Lazy execution | Trigger computation |\n",
    "| Return new RDD | Return value to driver |\n",
    "| map, filter, flatMap | collect, count, reduce |\n",
    "| groupBy, join, reduceByKey | take, first, saveAsTextFile |\n",
    "\n",
    "### 4. **Narrow vs Wide Transformations**\n",
    "\n",
    "| Narrow | Wide |\n",
    "|--------|------|\n",
    "| No shuffle required | Requires shuffle |\n",
    "| Fast, pipeline-able | Slower, expensive |\n",
    "| map, filter, flatMap | groupBy, join, reduceByKey |\n",
    "| Each input partition â†’ 1 output partition | Each input partition â†’ many output partitions |\n",
    "\n",
    "### 5. **When to Cache**\n",
    "- RDD used multiple times\n",
    "- Expensive to recompute\n",
    "- Iterative algorithms (ML, graph processing)\n",
    "- Interactive queries\n",
    "\n",
    "### 6. **Best Practices**\n",
    "- âœ… Prefer `reduceByKey()` over `groupByKey()` + reduce\n",
    "- âœ… Use `filter()` early to reduce data size\n",
    "- âœ… Cache RDDs that are reused multiple times\n",
    "- âœ… Use `take()` instead of `collect()` for large datasets\n",
    "- âœ… Minimize shuffles (wide transformations)\n",
    "- âš ï¸ Be careful with `collect()` - can crash driver with large data\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ Quick Reference\n",
    "\n",
    "### Creating RDDs\n",
    "```python\n",
    "sc.parallelize(collection)          # From collection\n",
    "sc.textFile(\"path/to/file\")        # From text file\n",
    "rdd.map(func)                      # From transformation\n",
    "```\n",
    "\n",
    "### Common Transformations\n",
    "```python\n",
    "rdd.map(lambda x: x * 2)           # Apply function\n",
    "rdd.filter(lambda x: x > 5)        # Filter elements\n",
    "rdd.flatMap(lambda x: x.split())   # Flatten results\n",
    "rdd.distinct()                      # Remove duplicates\n",
    "```\n",
    "\n",
    "### Common Actions\n",
    "```python\n",
    "rdd.collect()                       # Get all elements\n",
    "rdd.take(n)                        # Get first n elements\n",
    "rdd.count()                        # Count elements\n",
    "rdd.reduce(func)                   # Aggregate\n",
    "rdd.saveAsTextFile(\"path\")         # Save to file\n",
    "```\n",
    "\n",
    "### Pair RDD Operations\n",
    "```python\n",
    "rdd.groupByKey()                   # Group values by key\n",
    "rdd.reduceByKey(func)              # Reduce per key (preferred)\n",
    "rdd.sortByKey()                    # Sort by key\n",
    "rdd.join(other_rdd)                # Inner join\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Revision Checklist\n",
    "\n",
    "- [ ] Understand lazy evaluation and lineage\n",
    "- [ ] Know difference between transformations and actions\n",
    "- [ ] Understand narrow vs wide transformations\n",
    "- [ ] Know when to use cache/persist\n",
    "- [ ] Familiar with map vs flatMap\n",
    "- [ ] Understand groupByKey vs reduceByKey performance\n",
    "- [ ] Practice with text file operations\n",
    "- [ ] Comfortable with pair RDD operations (join, groupBy, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scheduler_agent (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
